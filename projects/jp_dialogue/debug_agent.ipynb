{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parlai.core.params import ParlaiParser\n",
    "from parlai.core.dict import DictionaryAgent\n",
    "from parlai.scripts.train_model import setup_args as tm_setupargs\n",
    "from parlai.scripts.train_model import TrainLoop\n",
    "from parlai.core.agents import create_agent\n",
    "from parlai.core.worlds import create_task\n",
    "import json\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHARED = {}\n",
    "def setup_interactive(shared):\n",
    "    parser = tm_setupargs()\n",
    "    parser.set_params(batchsize=5, beam_size=20, beam_min_n_best=10)\n",
    "    SHARED['opt'] = parser.parse_args([], print_args=True)\n",
    "\n",
    "    SHARED['opt']['task'] = 'projects.jp_dialogue.tasks.agents'\n",
    "    SHARED['opt']['model'] = 'bert_ranker/bi_encoder_ranker'\n",
    "#     SHARED['opt']['dict_class'] = 'projects.jp_dialogue.jp_retrieval.retrieval_agents:UniBiDictionaryAgent'\n",
    "#     SHARED['opt']['dict_build_first'] = True\n",
    "#     SHARED['opt']['dict_minfreq'] = 5\n",
    "    SHARED['opt']['model_file'] = '/installation/~/ParlAI/data/models/jp_dialogue/something_bert'\n",
    "    SHARED['opt']['no_cuda'] = True\n",
    "    SHARED['opt']['history_size'] = 1\n",
    "    SHARED['opt']['truncate'] = -1\n",
    "    SHARED['opt']['interactive_mode'] = True\n",
    "    SHARED['opt']['candidates'] = 'batch'\n",
    "    SHARED['opt']['eval_candidates'] = 'batch'\n",
    "    SHARED['opt']['encode_candidate_vecs'] = False\n",
    "    SHARED['opt']['fixed_candidates_path'] = ''\n",
    "    SHARED['opt']['fixed_candidate_vecs'] = 'reuse'\n",
    "#     SHARED['opt']['scoring_func'] = 'scaled'\n",
    "#     SHARED['opt']['embedding_size'] = 300\n",
    "#     SHARED['opt']['h_layer_num'] = 3\n",
    "#     SHARED['opt']['h_dim'] = 512\n",
    "#     SHARED['opt']['h_act_func'] = 'swish'\n",
    "#     SHARED['opt']['linear_dim'] = 1024\n",
    "#     SHARED['opt']['n_heads'] = 12\n",
    "#     SHARED['opt']['n_layers'] = 1\n",
    "#     SHARED['opt']['ffn_size'] = 3072\n",
    "#     SHARED['opt']['dropout'] = 0.1\n",
    "#     SHARED['opt']['attention_dropout'] = 0.1\n",
    "#     SHARED['opt']['relu_dropout'] = 0.0\n",
    "#     SHARED['opt']['learn_positional_embeddings'] = True\n",
    "#     SHARED['opt']['embeddings_scale'] = False\n",
    "#     SHARED['opt']['activation'] = 'gelu'\n",
    "#     SHARED['opt']['variant'] = 'xlm'\n",
    "#     SHARED['opt']['output_scaling'] = 1.0\n",
    "#     SHARED['opt']['eval_candidates'] = ''\n",
    "#     SHARED['opt']['learningrate'] = 5e-05\n",
    "#     SHARED['opt']['momentum'] = 0\n",
    "#     SHARED['opt']['optimizer'] = 'sgd'\n",
    "    SHARED['opt']['lr_scheduler'] ='reduceonplateau'\n",
    "    SHARED['opt']['out_dim'] =768\n",
    "    SHARED['opt']['add_transformer_layer']=False\n",
    "    SHARED['opt']['pull_from_layer']=-1\n",
    "    SHARED['opt']['bert_aggregation']='mean'\n",
    "    SHARED['opt']['dict_maxexs']=0\n",
    "    SHARED['opt']['train_folder']='rachel'\n",
    "    # Create model and assign it to the specified task\n",
    "    SHARED['world'] = TrainLoop(SHARED.get('opt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Main ParlAI Arguments: ] \n",
      "[  batchsize: 5 ]\n",
      "[  datapath: d:\\installation\\~\\parlai\\data ]\n",
      "[  datatype: train ]\n",
      "[  download_path: d:\\installation\\~\\parlai\\downloads ]\n",
      "[  hide_labels: False ]\n",
      "[  image_mode: raw ]\n",
      "[  init_opt: None ]\n",
      "[  multitask_weights: [1] ]\n",
      "[  numthreads: 1 ]\n",
      "[  show_advanced_args: False ]\n",
      "[  task: None ]\n",
      "[ ParlAI Model Arguments: ] \n",
      "[  dict_class: None ]\n",
      "[  init_model: None ]\n",
      "[  model: None ]\n",
      "[  model_file: None ]\n",
      "[ Training Loop Arguments: ] \n",
      "[  aggregate_micro: False ]\n",
      "[  dict_build_first: True ]\n",
      "[  display_examples: False ]\n",
      "[  eval_batchsize: None ]\n",
      "[  evaltask: None ]\n",
      "[  load_from_checkpoint: False ]\n",
      "[  max_train_time: -1 ]\n",
      "[  metrics: default ]\n",
      "[  num_epochs: -1 ]\n",
      "[  save_after_valid: False ]\n",
      "[  save_every_n_secs: -1 ]\n",
      "[  short_final_eval: False ]\n",
      "[  validation_cutoff: 1.0 ]\n",
      "[  validation_every_n_epochs: -1 ]\n",
      "[  validation_every_n_secs: -1 ]\n",
      "[  validation_max_exs: -1 ]\n",
      "[  validation_metric: accuracy ]\n",
      "[  validation_metric_mode: None ]\n",
      "[  validation_patience: 10 ]\n",
      "[  validation_share_agent: False ]\n",
      "[ Tensorboard Arguments: ] \n",
      "[  tensorboard_log: False ]\n",
      "[ PytorchData Arguments: ] \n",
      "[  batch_length_range: 5 ]\n",
      "[  batch_sort_cache_type: pop ]\n",
      "[  batch_sort_field: text ]\n",
      "[  numworkers: 4 ]\n",
      "[  pytorch_context_length: -1 ]\n",
      "[  pytorch_datapath: None ]\n",
      "[  pytorch_include_labels: True ]\n",
      "[  pytorch_preprocess: False ]\n",
      "[  pytorch_teacher_batch_sort: False ]\n",
      "[  pytorch_teacher_dataset: None ]\n",
      "[  pytorch_teacher_task: None ]\n",
      "[  shuffle: False ]\n",
      "[ Dictionary Loop Arguments: ] \n",
      "[  dict_include_test: False ]\n",
      "[  dict_include_valid: False ]\n",
      "[  dict_maxexs: -1 ]\n",
      "[  log_every_n_secs: 2 ]\n",
      "[ Dictionary Arguments: ] \n",
      "[  bpe_debug: False ]\n",
      "[  dict_endtoken: __end__ ]\n",
      "[  dict_file: None ]\n",
      "[  dict_initpath: None ]\n",
      "[  dict_language: english ]\n",
      "[  dict_lower: False ]\n",
      "[  dict_max_ngram_size: -1 ]\n",
      "[  dict_maxtokens: -1 ]\n",
      "[  dict_minfreq: 0 ]\n",
      "[  dict_nulltoken: __null__ ]\n",
      "[  dict_starttoken: __start__ ]\n",
      "[  dict_textfields: text,labels ]\n",
      "[  dict_tokenizer: re ]\n",
      "[  dict_unktoken: __unk__ ]\n",
      "[ ParlAI Image Preprocessing Arguments: ] \n",
      "[  image_cropsize: 224 ]\n",
      "[  image_size: 256 ]\n",
      "[ Current ParlAI commit: 78522a05ec036df9b2c6820ecf366ea46cf8ef88 ]\n",
      "[ building dictionary first... ]\n",
      "[ dictionary already built .]\n",
      "[ no model with opt yet at: /installation/~/ParlAI/data/models/jp_dialogue/something_bert(.opt) ]\n",
      "Dictionary: loading dictionary from /installation/~/ParlAI/data/models/jp_dialogue/something_bert.dict\n",
      "[ num words =  4 ]\n",
      "[BiEncoderRanker: full interactive mode on.]\n",
      "[setting fixed_candidates path to: /installation/~/ParlAI/data/models/jp_dialogue/something_bert.cands-projects.jp_dialogue.tasks.agents.cands ]\n",
      "Total parameters: 222415872\n",
      "Trainable parameters:  222415872\n",
      "[ Loading fixed candidate set from /installation/~/ParlAI/data/models/jp_dialogue/something_bert.cands-projects.jp_dialogue.tasks.agents.cands ]\n",
      "[ Vectorizing fixed candidate set (440 batch(es) of up to 512) ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████▋                                                 | 169/440 [00:15<00:24, 11.25it/s]"
     ]
    }
   ],
   "source": [
    "setup_interactive(SHARED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = SHARED['world'].world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_act = world.batch_act(0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.world.get_agents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_obs = world.batch_observe(1, batch_act, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_agent = world.world.get_agents()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_class = model_agent.dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v =[   1, 1869,  378,    5,    9,    2]\n",
    "for t in v:\n",
    "    print(dict_class.ind2bi[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = model_agent.batchify(batch_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cands, cand_vecs, label_inds = model_agent._build_candidates(\n",
    "            batch, source='batch', mode='train'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.text_vec.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model_agent.model(batch.text_vec, batch.bi_text_vec, cand_vecs['uni'], cand_vecs['bi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_uni = batch.text_vec\n",
    "x_bi = batch.bi_text_vec\n",
    "y_uni = cand_vecs['uni']\n",
    "y_bi = cand_vecs['bi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_emb, y_emb = model_agent.model.encode(x_uni, x_bi, y_uni.unsqueeze(1), y_bi.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_emb.expand(y_emb.size(0), x_uni.size(0), -1).transpose(0,1).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz, cand_num, seq_len = y_uni.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_emb.view(bsz, cand_num, -1).expand(y_emb.size(0), x_uni.size(0), -1).transpose(0,1).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_uni_emb = model_agent.model.y_unigram_encoder(y_uni.unsqueeze(1).view(bsz*cand_num, -1))\n",
    "y_bi_emb = model_agent.model.y_bigram_encoder(y_bi.unsqueeze(1).view(bsz*cand_num, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_uni_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_agent.model.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_emb.unsqueeze(1).expand(y_emb.view(bsz, cand_num, -1).expand(y_emb.size(0), x_uni.size(0), -1).transpose(0,1).contiguous().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_emb = y_emb.expand(cand_num, bsz, -1).transpose(0,1).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('/installation/~/ParlAI/data/models/bert_models/bert-wiki-ja/vocab.txt', tokenize_chinese_chars=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, 8, None, 17, 9444, None, 11, 14045, 57, 40, 57, 8]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(tokenizer.tokenize('そっち かぁ 。 どっち に しろ あめ は ふる な だ な 。'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
